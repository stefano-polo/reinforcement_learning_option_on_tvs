# Reinforcement Learning for Options on Target Volatility Funds
[![python](https://img.shields.io/badge/Python-3.7-3776AB.svg?style=flat&logo=python&logoColor=white)](https://www.python.org)
![Tests](https://github.com/stefano-polo/Option_on_Target_Volatility_Funds/actions/workflows/python-tests.yml/badge.svg)
![GitHub Tags](https://img.shields.io/github/tag/stefano-polo/Option_on_Target_Volatility_Funds.svg)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This repository contains code developed by the authors to address a stochastic optimal control problem related to option pricing in the financial world.
The library is designed to facilitate the application of deep reinforcement learning techniques for tackling this problem. It provides a structured framework to support the implementation of such techniques.
The work presented here was part of Stefano Polo's final project for his Master's degree in Physics.

For additional details about this work, we invite you to refer to our publication in the journal [Mathematical Methods in Economics and Finance](https://www.unive.it/pag/31137). This publication provides in-depth information on the research conducted and the findings obtained.

## Installation ‚öôÔ∏è

To build the project environment, the user just needs to run
```
./environment.sh
```

## License üìÑ
This project is licensed under the MIT License.

## Author
The repository is developed and maintained by:
- [Stefano Polo](https://github.com/stefano-polo)
## Collaborators ‚úçÔ∏è
People who worked on this project:
- [Roberto Daluiso](https://github.com/rdaluiso)
- [Andrea Pallavicini](https://github.com/pallavic)
- [Emanuele Nastasi](https://github.com/lele105nas)
